{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd0f966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system library\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "# useful libraries\n",
    "import math\n",
    "import operator\n",
    "import itertools\n",
    "import statistics\n",
    "import collections\n",
    "from collections import Counter\n",
    "from collections import OrderedDict\n",
    "\n",
    "# pandas\n",
    "import pandas as pd\n",
    "\n",
    "# numpy\n",
    "import numpy as np\n",
    "from numpy import std\n",
    "from numpy import mean\n",
    "from numpy import percentile\n",
    "\n",
    "# visualisarion\n",
    "import pydotplus\n",
    "import seaborn as sns\n",
    "from matplotlib import colors\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from IPython.display import Image\n",
    "\n",
    "# sklearn\n",
    "import sklearn\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# dimensional reducers\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif  # classification\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression  # regression\n",
    "\n",
    "# scalers\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# performance visualisation \n",
    "from sklearn import tree\n",
    "from scikitplot.metrics import plot_roc\n",
    "from scikitplot.metrics import plot_precision_recall\n",
    "from scikitplot.metrics import plot_cumulative_gain\n",
    "from scikitplot.metrics import plot_lift_curve\n",
    "from sklearn.model_selection import learning_curve\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "from yellowbrick.model_selection import LearningCurve\n",
    "from sklearn.metrics import auc, roc_curve, roc_auc_score \n",
    "\n",
    "# tree classifiers\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# linear classifiers\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# neighbors classifiers\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# naive_bayes classifiers\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# ensemble classifiers\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# nn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "plt.rcParams[\"patch.force_edgecolor\"] = True\n",
    "%matplotlib inline\n",
    "\n",
    "from yellowbrick.style import set_palette\n",
    "set_palette('bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1ac54f",
   "metadata": {},
   "source": [
    "### Global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e38c9204",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 10\n",
    "scoring = 'f1_weighted'\n",
    "random_state = 42\n",
    "\n",
    "# test_n_splits = 9\n",
    "test_n_splits = 3\n",
    "\n",
    "model = MLPClassifier(random_state=random_state)\n",
    "model_name = \"MLPClassifier\"\n",
    "\n",
    "learning_curve_flag = False\n",
    "v_or_t_flag = \"TST\"\n",
    "cmap = plt.cm.Greys\n",
    "color = \"grey\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58b9fd1",
   "metadata": {},
   "source": [
    "## Caricamento dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b7420d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train and y_train : ((7261, 200),(7261, 1))\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../data/reduced_cleaned_files/train_reduced_cleaned_4.csv')\n",
    "X_train = train.drop(['Activity'], axis=1)\n",
    "y_train = train['Activity']\n",
    "y_train = pd.DataFrame(y_train)\n",
    "\n",
    "print('X_train and y_train : ({},{})'.format(X_train.shape, y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6962ed7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test and y_test : ((2947, 200),(2947, 1))\n"
     ]
    }
   ],
   "source": [
    "X_test = pd.read_csv('../data/reduced_files/X_test_reduced_UFS.csv')\n",
    "y_test = pd.read_csv('../data/csv_files/y_test.csv')\n",
    "#X_train = train.drop(['subject', 'Activity','ActivityName'], axis=1)\n",
    "\n",
    "#y_train = train['Activity']\n",
    "#y_train = pd.DataFrame(y_train)\n",
    "print('X_test and y_test : ({},{})'.format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1984865c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7261, 200) (2947, 200)\n",
      "(7261, 1) (2947, 1)\n"
     ]
    }
   ],
   "source": [
    "X_tr = X_train.copy()\n",
    "y_tr = y_train.copy()\n",
    "X_ts = X_test.copy()\n",
    "y_ts = y_test.copy()\n",
    "\n",
    "print(X_tr.shape, X_ts.shape)\n",
    "print(y_tr.shape, y_ts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e475299c",
   "metadata": {},
   "source": [
    "# MLPClassifier (baseline classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b720c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_baseline_classification(X_tr, y_tr, X_ts, y_ts):\n",
    "    fitted_model = model.fit(X_tr, y_tr.values.ravel())\n",
    "    y_pred = model.predict(X_ts)\n",
    "    \n",
    "    print(confusion_matrix(y_ts, y_pred))\n",
    "    print(classification_report(y_ts, y_pred))\n",
    "    \n",
    "    try:\n",
    "        features_importance = sorted(zip(X_tr.columns, fitted_model.feature_importances_),reverse=True)\n",
    "        # print(features_importance)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        features_importance = sorted(zip(X_tr.columns, fitted_model.coef_),reverse=True)\n",
    "        # print(features_importance)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67ddd135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[477  18   1   0   0   0]\n",
      " [ 45 420   6   0   0   0]\n",
      " [  4  11 405   0   0   0]\n",
      " [  0   4   0 422  65   0]\n",
      " [  0   0   0  31 501   0]\n",
      " [  0   0   1   0   0 536]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      0.96      0.93       496\n",
      "           2       0.93      0.89      0.91       471\n",
      "           3       0.98      0.96      0.97       420\n",
      "           4       0.93      0.86      0.89       491\n",
      "           5       0.89      0.94      0.91       532\n",
      "           6       1.00      1.00      1.00       537\n",
      "\n",
      "    accuracy                           0.94      2947\n",
      "   macro avg       0.94      0.94      0.94      2947\n",
      "weighted avg       0.94      0.94      0.94      2947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_baseline_classification(X_train, \n",
    "                              y_train, \n",
    "                              X_test, \n",
    "                              y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160114f7",
   "metadata": {},
   "source": [
    "# Tuned MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18db2e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_layer(X_tr):\n",
    "    n_features = X_tr.shape[1]\n",
    "    layers = []\n",
    "    for i in range(1, (n_features + 1)):\n",
    "        layer = (i, )\n",
    "        layers.append(layer)\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb198d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_second_layer(X_tr):\n",
    "    n_features = X_tr.shape[1]\n",
    "    layers = []\n",
    "    for i in range(1, (n_features + 1)):\n",
    "        for j in range(1, (n_features + 1)):\n",
    "            layer = (i, j)\n",
    "            layers.append(layer)\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2fa2fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_third_layer(X_tr):\n",
    "    n_features = X_tr.shape[1]\n",
    "    layers = []\n",
    "    for i in range(1, (n_features + 1)):\n",
    "        for j in range(1, (n_features + 1)):\n",
    "            for k in range(1, (n_features + 1)):\n",
    "                layer = (i, j, k)\n",
    "                layers.append(layer)\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "032d6f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fourth_layer(X_tr):\n",
    "    n_features = X_tr.shape[1]\n",
    "    layers = []\n",
    "    for i in range(1, (n_features + 1)):\n",
    "        for j in range(1, (n_features + 1)):\n",
    "            for k in range(1, (n_features + 1)):\n",
    "                for l in range(1, (n_features + 1)):\n",
    "                    layer = (i, j, k, l)\n",
    "                    layers.append(layer)\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd621c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_grid(X_tr):\n",
    "    grid = dict()\n",
    "    n_features = X_tr.shape[1]\n",
    "    grid['model__hidden_layer_sizes'] = get_first_layer(X_tr) +get_second_layer(X_tr) + get_third_layer(X_tr) + get_fourth_layer(X_tr)\n",
    "    grid['model__activation'] = ['identity', 'logistic', 'tanh', 'relu']\n",
    "    grid['model__learning_rate'] = ['constant', 'invscaling', 'adaptive']\n",
    "    grid['model__tol'] = [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0]\n",
    "    grid['model__alpha'] = [0.0001, 0.001, 0.01, 0.1, 1.0]\n",
    "    grid['model__momentum'] =  list(np.arange(0.1, 1.1, 0.1))\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "207277e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT FUNCTIONS\n",
    "def plot_roc_curve(y_ts, y_prob):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plot_roc(y_ts, y_prob)\n",
    "    plt.title(\"%s\\'s %s ROC curve\" % (model_name, v_or_t_flag.upper()))\n",
    "    plt.show()\n",
    "    \n",
    "def plot_precision_recall_curve(y_ts, y_prob):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plot_precision_recall(y_ts, y_prob)\n",
    "    plt.title(\"%s\\'s %s Precision-Recall curve\" % (model_name, v_or_t_flag.upper()))\n",
    "    plt.show()\n",
    "    \n",
    "def plot_cumulative_gain_curve(y_ts, y_prob):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plot_cumulative_gain(y_ts, y_prob)\n",
    "    plt.title(\"%s\\'s %s Cumulative Gains curve\" % (model_name, v_or_t_flag.upper()))\n",
    "    plt.show()\n",
    "    \n",
    "def plot_lift_curve_curve(y_ts, y_prob):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plot_lift_curve(y_ts, y_prob)\n",
    "    plt.title(\"%s\\'s %s Lift curve\" % (model_name, v_or_t_flag.upper()))\n",
    "    plt.show()\n",
    "    \n",
    "def plot_confusion_matrix(cm, classes, normalize):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(\"%s\\'s %s classification report\" % (model_name, v_or_t_flag.upper()))\n",
    "    # plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    plt.grid(False)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_classification_report(y_ts, y_pred):\n",
    "    model_report = classification_report(y_ts, \n",
    "                                       y_pred,\n",
    "                                       # target_names=['Studio Recording', 'Live Recording'],\n",
    "                                       output_dict=True)\n",
    "    model_r = pd.DataFrame(model_report).iloc[:-1, :].T\n",
    "    sns.heatmap(model_r, annot=True, cmap=cmap, cbar=False)\n",
    "    plt.title(\"%s\\'s %s confusion matrix\" % (model_name, v_or_t_flag.upper()))\n",
    "    plt.show()\n",
    "    \n",
    "def plot_decision_boundary(X_tr, y_tr, scaler, model):\n",
    "    try:\n",
    "        pca = PCA(n_components=2)\n",
    "        best_visualisation_scaler = StandardScaler()\n",
    "        scaled_X_tr = best_visualisation_scaler.fit_transform(X_tr)\n",
    "        X = pca.fit_transform(scaled_X_tr)\n",
    "        # X = pca.fit_transform(X_tr)\n",
    "        y = y_tr.values.ravel()\n",
    "\n",
    "        model.fit(X, y)\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        fig = plot_decision_regions(X=X, y=y, clf=model, legend=2)\n",
    "        plt.xlabel(\"PCA component 1\")\n",
    "        plt.ylabel(\"PCA component 2\")\n",
    "        plt.title(\"%s's %s decision boundary\" % (model_name, v_or_t_flag))\n",
    "        plt.legend(loc='best')\n",
    "        plt.grid(False)\n",
    "        plt.show()\n",
    "    except ValueError:\n",
    "        return\n",
    "\n",
    "def spot_errors(test_label, test_pred):  \n",
    "    spot_errors = []\n",
    "    label_errors = []\n",
    "    for i in range(len(test_label)):\n",
    "        if test_label[i] != test_pred[i]:\n",
    "            spot_errors.append('darkred')\n",
    "            label_errors.append(\"wrong prediction\")\n",
    "        else:\n",
    "            spot_errors.append('darkgray')\n",
    "            label_errors.append(\"correct prediction\")\n",
    "    return spot_errors, label_errors\n",
    "\n",
    "def classification_visualizer(test_set, test_label, test_pred):\n",
    "    test_label = test_label.values\n",
    "    \n",
    "    f, axs = plt.subplots(nrows=1, ncols=3, figsize=(24,8))\n",
    "    errors, label_errors = spot_errors(test_label, test_pred)\n",
    "    labels = [test_label, test_pred, errors]\n",
    "    titles = ['True Labels', 'Predicted Labels', 'Misclassifications']\n",
    "    \n",
    "    for i in range(0, 3):\n",
    "        axs[i].scatter(test_set[missclassif_column_name1], test_set[missclassif_column_name2], c=labels[i], cmap='cividis')\n",
    "        axs[i].set_title(titles[i])\n",
    "        axs[i].set_xlabel(missclassif_column_name1, fontdict={'fontsize': 'large'})\n",
    "        axs[i].set_ylabel(missclassif_column_name2, fontdict={'fontsize': 'large'})\n",
    "        \n",
    "    plt.suptitle('Visualization of the ' + model_name + ' classifier on the %s' % v_or_t_flag)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def error_visualizer(test_set, test_label, test_pred, column_name1, column_name2):\n",
    "    test_label = test_label.values\n",
    "    errors, label_errors = spot_errors(test_label, test_pred)\n",
    "    \n",
    "    palette = ['darkgray', 'darkred']\n",
    "    if errors[0] == 'darkred':\n",
    "        palette = ['darkred', 'darkgray']\n",
    "    \n",
    "    fig = plt.figure(figsize=(5, 6))\n",
    "    sns.scatterplot(x=test_set[column_name1], y=test_set[column_name2], hue=label_errors, palette=palette)\n",
    "    plt.title('%s\\'s %s misclassifications' % (model_name, v_or_t_flag))\n",
    "    plt.xlabel(column_name1)\n",
    "    plt.ylabel(column_name2)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_learning_curve(X_tr, y_tr, model, v_or_t_flag):\n",
    "    second_score = \"\"\n",
    "    if v_or_t_flag == 'VAL':\n",
    "        cv = StratifiedKFold(n_splits=validation_n_splits)\n",
    "        second_score = \"Validation score\"\n",
    "    else:\n",
    "        cv = StratifiedKFold(n_splits=test_n_splits)\n",
    "        second_score = \"Test score\"\n",
    "    sizes = np.linspace(0.3, 1.0, 10)\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    visualizer = LearningCurve(model, cv=cv, scoring=scoring, train_sizes=sizes, \n",
    "                                                                       n_jobs=-1, random_state=random_state)\n",
    "\n",
    "    visualizer.fit(X_tr, y_tr.values.ravel())    \n",
    "    # visualizer.ax.get_lines()[1].set_label(second_score)\n",
    "    visualizer.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b727f3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tuned_model(X_tr, y_tr, params):\n",
    "    \n",
    "    X_tr_curr = X_tr.copy()\n",
    "    \n",
    "    model_params = list(model_grid(X_tr_curr).keys())\n",
    "    try:\n",
    "        n_bins = params['preprocessor__numeric__discretizer__n_bins'] \n",
    "        strategy = params['preprocessor__numeric__discretizer__strategy']\n",
    "        encode = params['preprocessor__numeric__discretizer__encode']\n",
    "        discretizer = KBinsDiscretizer(encode=encode, n_bins=n_bins, strategy=strategy)\n",
    "        # scale data\n",
    "        X_tr_curr = discretizer.fit_transform(X_tr_curr.values)\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        scaler = params['preprocessor__numeric__discretizer__scaler']\n",
    "        # scale data\n",
    "        X_tr_curr = scaler.fit_transform(X_tr_curr.values)\n",
    "    except KeyError:\n",
    "        pass\n",
    "    \n",
    "    # retrieve best hyperameters\n",
    "    tmp_model_hyperparameters = dict((k, params[k]) for k in model_params if k in params)\n",
    "    model_hyperparameters = {}\n",
    "    for key, value in tmp_model_hyperparameters.items():\n",
    "        key = key.split('model__')[1].replace(\"'\", \"\")\n",
    "        model_hyperparameters[key] = value\n",
    "        \n",
    "    tuned_model =  model.set_params(**model_hyperparameters)\n",
    "    tuned_model.fit(X_tr_curr, y_tr.values.ravel())\n",
    "    \n",
    "    plot_decision_boundary(X_tr_curr, y_tr, MinMaxScaler(), tuned_model)  # passing random scaler\n",
    "    \n",
    "    if learning_curve_flag:\n",
    "        plot_learning_curve(X_tr_curr, y_tr, tuned_model, v_or_t_flag)\n",
    "    \n",
    "    return tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb649520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(X_tr, y_tr, X_ts, y_ts, numeric_features, categorical_features, discretizer_flag, \n",
    "                                                            scaler_flag, feature_filter_key, feature_flag):\n",
    "    \n",
    "    # define the evaluation method\n",
    "    cv = StratifiedKFold(n_splits=test_n_splits)\n",
    "\n",
    "    # construct the pipeline to evaluate\n",
    "    # scaler = RobustScaler()\n",
    "    grid=model_grid(X_tr)\n",
    "    steps = [('model', model)]\n",
    "        \n",
    "    if feature_filter_key == 'anova':\n",
    "        anova = SelectKBest(score_func=f_classif)\n",
    "        steps.insert(0, ('anova', anova))\n",
    "        grid['anova__k'] = [i+1 for i in range(X_tr.shape[1])]\n",
    "    elif feature_filter_key == 'rfe':\n",
    "        rfe = RFE(estimator=DecisionTreeClassifier())\n",
    "        steps.insert(0, ('rfe', rfe))\n",
    "        grid['rfe__estimator'] = [DecisionTreeClassifier(), LogisticRegression(max_iter=10000)]\n",
    "        grid['rfe__n_features_to_select'] = [i+1 for i in range(X_tr.shape[1])]\n",
    "    \n",
    "    # construct feature type's column transformer\n",
    "    numeric_steps = []\n",
    "    if scaler_flag:      # continous variable normalisation/standardisation\n",
    "        numeric_steps.insert(0, ('scaler', None))\n",
    "        grid['preprocessor__numeric__scaler'] = [MinMaxScaler(), MaxAbsScaler(), StandardScaler(), RobustScaler()]\n",
    "                      \n",
    "    if discretizer_flag:  # continous variable binning\n",
    "        numeric_steps.insert(0, ('discretizer', KBinsDiscretizer(encode='ordinal')))  # ordinal bins\n",
    "        grid['preprocessor__numeric__discretizer__n_bins'] = list(range(2, 11))\n",
    "        grid['preprocessor__numeric__discretizer__strategy'] = ['uniform', 'quantile', 'kmeans']\n",
    "        \n",
    "    numeric_transformer = None\n",
    "    if len(numeric_steps) > 0:\n",
    "        numeric_transformer = Pipeline(steps=numeric_steps)\n",
    "        preprocessor = ColumnTransformer(\n",
    "        transformers=[('numeric', numeric_transformer, numeric_features)])\n",
    "        # add numeric ColumnTransformer to global Pipeline\n",
    "        steps.insert(0, ('preprocessor', preprocessor))\n",
    "        \n",
    "    # define the pipeline to evaluate\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    \n",
    "    # define the grid search\n",
    "    # search = GridSearchCV(pipeline, grid, scoring='f1_weighted', n_jobs=-1, cv=cv, verbose=2)\n",
    "    search = RandomizedSearchCV(pipeline, grid, scoring=scoring, n_jobs=-1, \n",
    "                                n_iter=n_iter, cv=cv, verbose=2, refit=scoring, random_state=random_state)\n",
    "    \n",
    "    # perform the search\n",
    "    results = search.fit(X_tr, y_tr.values.ravel())\n",
    "    \n",
    "    # summarize best\n",
    "    score = results.best_score_\n",
    "    params = results.best_params_\n",
    "    print('Best Mean F1_weighted: %.3f ' % score)\n",
    "    print('Best Config: %s ' % params)\n",
    "    \n",
    "    # perform classification (linear model doesn't predict an integer value => no predict_proba)\n",
    "    y_pred = search.predict(X_ts)\n",
    "    y_prob_flag = True\n",
    "    try:\n",
    "        y_prob = search.predict_proba(X_ts)\n",
    "    except:\n",
    "        y_prob = y_pred\n",
    "        y_prob_flag = False\n",
    "    \n",
    "    best_features, best_features_scores = [], []\n",
    "    if feature_filter_key != \"\":\n",
    "        best_features, best_features_scores = get_best_features_grid_cv(X_tr, y_tr, results, feature_filter_key)\n",
    "        X_tr = X_tr[best_features]\n",
    "    \n",
    "    # retrieve the tuned model\n",
    "    tuned_model = get_tuned_model(X_tr, y_tr, params)\n",
    "    if tuned_model !=  pipeline['model']:\n",
    "        print(\"Difference in tuned model and pipeline\")\n",
    "        print(\"tuned_model\", tuned_model)\n",
    "        print(\"pipe\", pipeline['model'])\n",
    "        # print(\"estimator\", results.estimator)\n",
    "        sys.exit(-1)\n",
    "    \n",
    "    # plots\n",
    "    if feature_flag and (feature_filter_key == \"\"):\n",
    "        best_features, best_features_scores = get_feature_importances_or_coef(X_tr, y_tr, tuned_model)\n",
    "    elif (feature_flag) and (feature_filter_key != \"\"):\n",
    "        _ , _ = get_feature_importances_or_coef(X_tr, y_tr, tuned_model)\n",
    " \n",
    "    cm = confusion_matrix(y_ts, y_pred)\n",
    "    plot_confusion_matrix(cm, results.classes_, True)\n",
    "    plot_classification_report(y_ts, y_pred)\n",
    "    \n",
    "    if y_prob_flag:\n",
    "        plot_roc_curve(y_ts, y_prob)\n",
    "        plot_precision_recall_curve(y_ts, y_prob)\n",
    "        #plot_cumulative_gain_curve(y_ts, y_prob)\n",
    "        #plot_lift_curve_curve(y_ts, y_prob)\n",
    "    else:\n",
    "        print(\"roc\", roc_auc_score(y_ts.values.ravel(), y_pred, average=\"weighted\"))\n",
    "        sklearn.metrics.plot_roc_curve(results, X_ts, y_ts.values.ravel())  \n",
    "        plt.show()\n",
    "    \n",
    "    # plot_decision_boundary(X_tr, y_tr, MinMaxScaler(), tuned_model)  # passing random scaler\n",
    "    # plot_learning_curve(X_tr, y_tr, tuned_model)\n",
    "    # error_visualizer(not_scale_X_ts, y_ts, y_pred, 'chroma_cens_02', 'track_duration')\n",
    "    \n",
    "    return params, tuned_model, y_pred, y_prob, best_features, best_features_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8b6b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_tst, tuned_model_tst, y_pred_tst, y_prob_tst, best_features, best_features_scores = \\\n",
    "                                                    grid_search(X_tr=X_tr, \n",
    "                                                                y_tr=y_tr,\n",
    "                                                                X_ts=X_ts, \n",
    "                                                                y_ts=y_ts,\n",
    "                                                                numeric_features=X_train.columns, \n",
    "                                                                categorical_features=X_train.columns, \n",
    "                                                                discretizer_flag=False,\n",
    "                                                                scaler_flag=True, \n",
    "                                                                feature_filter_key=\"\", \n",
    "                                                                feature_flag=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4ef552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(X_tr, y_tr, model, v_or_t_flag):\n",
    "    second_score = \"\"\n",
    "    if v_or_t_flag == 'VAL':\n",
    "        cv = StratifiedKFold(n_splits=validation_n_splits)\n",
    "        second_score = \"Validation score\"\n",
    "    else:\n",
    "        cv = StratifiedKFold(n_splits=test_n_splits)\n",
    "        second_score = \"Test score\"\n",
    "        \n",
    "    my_title = model_name + \"'s %s Learning Curve\" % (v_or_t_flag) \n",
    "        \n",
    "    sizes = np.linspace(0.3, 1.0, 10)\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    visualizer = LearningCurve(model, cv=cv, scoring=scoring, train_sizes=sizes, \n",
    "                                                        n_jobs=-1, random_state=random_state, title=my_title)\n",
    "\n",
    "    visualizer.fit(X_tr, y_tr.values.ravel())    \n",
    "    # visualizer.ax.get_lines()[1].set_label(second_score)\n",
    "    visualizer.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649facbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_or_t_flag = \"TST\"\n",
    "plot_learning_curve(X_train, \n",
    "                    y_train, \n",
    "                    tuned_model_tst, \n",
    "                    v_or_t_flag)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
